# Gather, Sort and Contemplate. A novel approach to problem solving with Large Language Models.
# GSaC is a novel approach to problem solving with Large Language Models (LLMs) that is based on the idea of using the LLM to gather, sort and contemplate information in order to solve a complex problem. The GSaC approach is based on the idea that LLMs can be used to gather information from a wide range of sources, sort that information into a coherent and useful form, and then contemplate that information in order to solve a complex problem. The GSaC approach begins with the collection of related resources. They are sorted using labeling and categorization. The customizable colors of Github Issues Labels offer an additional layer of information to be used in the sorting process. The contemplation phase is where the LLM is used to analyze the sorted information, synthesize new ideas, and, ultimately, solve the problem. The GSaC approach is a novel way to use LLMs to solve complex problems, and it has the potential to be a powerful tool for problem solving in a wide range of domains.

## Gather
Github Issues are used as the initial warehouse of information. Resources, such a papers, articles, repositories and gists are collected and labeled, initially by humans. After a number of samples are labeled, the AI can be used to automate the labeling process. The AI can also be used to suggest additional labels based on the content of the resources. I suggest a progressing handover of the labeling process from human to model, to ensure the quality of the labels. 
## Logprobs: Using logprobs are used to estimate the model's confidence in the label prediction and displaying that data with the proposed new labels. For now, this is only applied to the creation of brand new labels and not to the selection of existing labels. Though this could be a future feature. We could, either predict each label individually, or (as we do now) predict all labels at once and calculate the logprobs over the sequence of labels. We could then automatically regenerate the request if the logprobs are below a certain threshold. 

For creating new labels, I currently demand a confidence of .99 for the model suggested new label to be created.

Apart from labeling, it is also a good idea to include a quote from the resource, chosen by a human to highlight the most important part of the resource. Particularly important for new concepts or ideas that are not in the model's training data. For now, I allow highlighting a single block only. You can highlight an entire webpage in one block, of course, and this may be necessary for some resources, like online manuals such as readthedocs, if they are well organised.

## Contemplate: Next step is to allow the llm to ingest these and begin to synthesise new ideas from them.