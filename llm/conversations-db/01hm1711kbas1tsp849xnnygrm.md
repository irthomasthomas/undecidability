**Prompt:**
Make this content into a pretty gh markdown note:quote:- [ ] [mit-han-lab/streaming-llm: Efficient Streaming Language Models with Attention Sinks](https://github.com/mit-han-lab/streaming-llm)\n
Abstract\n
#### Suggested labels
#### {   "key": "sparse-computation",   "value": "Using ReLU llms, like mixtral moe, for efficient computation" }

**Response:**
> **Note:**
> 
> - [ ] [mit-han-lab/streaming-llm: Efficient Streaming Language Models with Attention Sinks](https://github.com/mit-han-lab/streaming-llm)
> 
> **Abstract**
> 
> #### Suggested labels
> 
> #### {   "key": "sparse-computation",   "value": "Using ReLU llms, like mixtral moe, for efficient computation" }

<details><summary>Metadata</summary>

- Duration: 2025 ms
- Datetime: 2024-01-13T10:49:03.362302
- Model: gpt-3.5-turbo-0613

</details>

**Options:**
```json
{"temperature": 0.1}
```

